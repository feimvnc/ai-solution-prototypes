{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4b58c3-d5c0-4347-9814-91c7f11b27cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A script to fine-tune model using own datasets\n",
    "\n",
    "# https://www.youtube.com/watch?v=ZqoZDI0p1aI\n",
    "# Fine Tune DeepSeek Model on your Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c0e1795-c8e3-4149-a5d0-82c200351de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets sympy wandb\n",
    "# !pip install --no-cache-dir bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68bcd846-8f21-4af0-884a-092b330c70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to('cuda') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148c7fc2-7eb5-4391-b943-749879daf15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model information\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf7ee9d-91cf-4e25-a6b1-c0454d1ac15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dataset\n",
    "import json \n",
    "\n",
    "# Define samples for fine-tuning, more samples needed for real fine tuning\n",
    "# source from below\n",
    "# https://github.com/aws-samples/amazon-sagemaker-fine-tuning-seq2seq-model-example/blob/main/sample_data/test.csv\n",
    "samples = [\n",
    "    {\n",
    "        \"prompt\": \"note 1: Patient was admitted to the hospital with acute pancreatitis. CT scan showed pancreatic necrosis, and the patient was started on antibiotics and enteral nutrition. The patient's heart rate was 110 beats per minute, and blood pressure was 150/100 mmHg. The patient's condition improved over the course of treatment, and repeat imaging showed resolution of the necrosis.\",\n",
    "        \"completion\": \"summary 1: Acute pancreatitis, antibiotics, enteral nutrition, HR 110, BP 150/100.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"note 1: Patient was admitted to the hospital with acute exacerbation of heart failure. Echocardiogram showed reduced ejection fraction and severe aortic stenosis. The patient was started on diuretics and underwent aortic valve replacement surgery. The patient's heart rate was 80 beats per minute, and blood pressure was 120/80 mmHg. The patient's cardiac function improved over the course of treatment.\",\n",
    "        \"completion\": \"summary 2: Heart failure exacerbation, aortic stenosis, diuretics, surgery, HR 80, BP 120/80.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"note 1: Patient has a history of type 2 diabetes and was admitted to the hospital with hyperglycemia. Blood glucose levels were elevated at 400 mg/dL on arrival, and insulin therapy was initiated. The patient's heart rate was 100 beats per minute, and blood pressure was 140/90 mmHg. The patient's blood glucose levels improved over the course of treatment.\",\n",
    "        \"completion\": \"summary 3: Type 2 diabetes, hyperglycemia, insulin therapy, HR 100, BP 140/90.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"note 1: Patient was admitted to the ICU with severe traumatic brain injury. CT scan showed diffuse axonal injury, and the patient underwent intracranial pressure monitoring and was started on barbiturate therapy. The patient's heart rate was 70 beats per minute, and blood pressure was 110/70 mmHg. The patient's neurological status improved over the course of treatment, and repeat imaging showed reduction in the intracranial pressure.\",\n",
    "        \"completion\": \"summary 4: Traumatic brain injury, diffuse axonal injury, ICP monitoring, barbiturate therapy, HR 70, BP 110/70.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"note 2: Patient presented with fever and productive cough. Chest X-ray showed a cavitary lesion in the right upper lobe, and the patient was diagnosed with pulmonary tuberculosis. The patient was started on antituberculosis therapy and monitored for side effects. The patient's heart rate was 90 beats per minute, and blood pressure was 130/80 mmHg. The patient's condition improved over the course of treatment.\",\n",
    "        \"completion\": \"summary 5: Pulmonary tuberculosis, antituberculosis therapy, HR 90, BP 130/80.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f90da376-9fd7-4e66-8d95-bc901c47148a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_dataset.jsonl is created!\n"
     ]
    }
   ],
   "source": [
    "# write sample to jsonl file\n",
    "file_name = \"custom_dataset.jsonl\"\n",
    "with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    for sample in samples:\n",
    "        json_line = json.dumps(sample, ensure_ascii=False)\n",
    "        f.write(json_line + \"\\n\")\n",
    "print(f\"{file_name} is created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceca1f1-2a8d-4bdd-b17d-1ecdfb562c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd; ls -l custom_dataset.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "663f9ddf-b916-4865-ba05-3bb1c6dd2c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# login wandb\n",
    "import wandb\n",
    "# wandb.login()   # uncomment to login once to view fine-tune metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7fc941-9fc0-4cd1-ad6f-f59e93b0a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project = \"fine-tune-custom-dataset\",\n",
    "    config = {\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"architecture\": \"DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "        \"dataset\": \"custom_dataset.jsonl\",\n",
    "        \"epochs\": 2,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d61d6bc3-a127-498f-8455-61bc8b996d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5460d57326843d3b7e6a8ca37f67f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('json', data_files='custom_dataset.jsonl', split=\"train\")\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9c27827-98e7-429b-a9d2-9044614c935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bbdbaa5-01c6-48dd-9b95-5d3b855dc052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a369d3318bb24451af2b3112e0860d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3c0a74d0af45fbac842e962e556e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    combined_texts = [f'{prompt}\\n{completion}' for prompt, completion in zip(examples[\"prompt\"], examples[\"completion\"])] \n",
    "    tokenized = tokenizer(combined_texts, truncation=True, max_length=512, padding=\"max_length\")\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431d0054-d69d-4deb-8472-10beb33483f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install 'accelerate>=0.26.0'\n",
    "# !pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c56c77e-5b30-4240-aae3-125d741a4425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cpu training\n",
    "# !pip install 'accelerate>=0.26.0'\n",
    "\n",
    "#\n",
    "from transformers import BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit = True\n",
    ")\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=quantization_config, device_map=\"auto\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=quantization_config, low_cpu_mem_usage=True) #, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d07167a-5d2d-4666-a7c2-2f91f23e7689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "loar_config = LoraConfig(\n",
    "    r=8, lora_alpha=16, lora_dropout=0.05, task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc40d9c1-519a-47e6-970e-ba1f3da5a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArgument, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./deepseek_finetuned\",\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=16,\n",
    "    fp16=True,\n",
    "    logging_step=10,\n",
    "    save_steps=100,\n",
    "    evaluation_stragegy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    learning_rage=3e-5, # 0.00003\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"DeepSeek_FineTuning_Experiment\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f382fb-5ab8-4eb1-9a82-0f234e31ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d0500-0d61-4ffe-ae14-24a00b8b78dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c05af5-046d-4253-b686-99e54d8dd303",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./deepseek_finetuned\"\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "print(f\"{save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714c6e6a-623c-49d7-b161-e505ca40e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge lora \n",
    "from peft import PeftModel\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model = PeftModel.from_pretrained(base_model, save_path)   # base model + lora\n",
    "model = model.merge_and_unload()  # merge model\n",
    "\n",
    "final_save_path=\"./deepseek_finetuned\"\n",
    "model.save_pretrained(final_save_path)\n",
    "tokenzier.save_pretrained(final_save_path)\n",
    "print(f'{final_save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce54edc7-7f56-4b9d-a252-eab95f129556",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(final_save_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(final_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e9d98-9889-433d-b97f-b067a6c39fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42072f0a-2ed1-4093-81c0-baca09ba4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask question to fine-tuned model\n",
    "prompt=\"Summarize the text - Patient was admitted to the hospital with acute pancreatitis. CT scan showed pancreatic necrosis, and the patient was started on antibiotics and enteral nutrition. The patient's heart rate was 110 beats per minute, and blood pressure was 150/100 mmHg. The patient's condition improved over the course of treatment, and repeat imaging showed resolution of the necrosis.\"\n",
    "generated_texts = pipe(prompt, max_length=300, num_return_sequence=1)\n",
    "generated_text = generated_texts[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836cfb7a-9aef-4c96-bfd4-69f448868f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
